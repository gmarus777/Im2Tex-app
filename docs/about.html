<!DOCTYPE html>
<html>

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>About</title>
    <link rel="stylesheet" href="styles.css">
</head>

<body>
    <!-- Navigation menu -->
    <header>
         <nav>
            <!-- Logo -->
            <div class="logo">
            <span class="logo-text">Im<span class="logoright-accent">2</span><span class="logo-accent">Tex</span></span>
             </div>
             <ul>
                <li><a href="index.html" target="_self">Home</a></li>
                  <li><a href="model.html" target="_self">Model</a></li>
                 <li><a href="generate.html" target="_self">Dataset</a></li>
                <li><a href="about.html" target="_self">About </a></li>

            </ul>
            <div class="menu-btn">
                <i class="fas fa-bars"></i>
            </div>
        </nav>
    </header>


    <!-- About Us section -->
    <section id="about">
        <h2>About </h2>
        <p>Based on Im2Tex project available on Github   
            <a href="https://github.com/gmarus777/image-to-tex-OCR">
            <img src="https://img.shields.io/badge/image--to--Tex--OCR-visit-a?style=social&logo=github" alt="Description of the image">
        </a>
            </p>
    </section>




<div style="text-align: center;">
    <section id="What it does">
        <h2>What it does </h2>
        <div style="display: flex; flex-direction: column; align-items: center; max-width: 800px; margin: 0 auto; text-align: left;">
        <p>

            <span style="color: black;font-weight: bold">Im</span><span style="color: rgb(42, 150, 140);font-weight: bold">2</span><span style="color: rgb(221, 102, 154);font-weight: bold">Tex</span>  is a tool designed to simplify the process of converting images containing mathematical formulas (in formats such as PNG and JPEG) into LaTeX code. 
            Our system utilizes a combination of Convolutional Neural Network (CNN) backbone and Transformer decoder model
             and accurately recognize and interpret complex mathematical symbols, expressions, and equations within the images.
              The tool is highly versatile, user-friendly, and ensures precise conversion into LaTeX code.
        </div>
    </section>
</div>

<div style="text-align: center;">
    <section id="How it was built">
        <h2>How it was built</h2>
        <div style="display: flex; flex-direction: column; align-items: center; max-width: 800px; margin: 0 auto; text-align: left;">
        <p> Our starting point was
             <a href="https://im2markup.yuntiandeng.com" target="_blank">the Image-to-Markup project</a>
             developed by the Harvard NLP group, which served as a valuable template. 
            We then customized and revamped the data generation tools based on our needs and findings,
            culminating in the creation of our data generation project,
            <a href="https://github.com/gmarus777/Printed-Latex-Data-Generation" target="_blank">Printed-Latex-Data-Generation</a>
            This project enables users to parse ArXiv papers, extract LaTeX code, and generate corresponding .png images
            and LaTeX code labels. Our data generation tools offer customization for resolution,
             as we discovered that higher resolution training data significantly impacts model performance.
            Our 
            <a href="https://zenodo.org/record/7738969#.ZDWIQy-B2Lc" target="_blank">generated dataset</a>
             demonstrates the capabilities of our data generation tools. Subsequently,
              we turned to the preprint by S. Singh 2018
              <a href="https://arxiv.org/abs/1802.05415" target="_blank">Image-to-Markup Generation with Coarse-to-Fine Attention</a>
               as
                a foundation for our image-to-LaTeX model development. Our final model employs
                 a CNN ResNet34 backbone and a Transformer decoder. Extensive work has been dedicated
                  to preprocessing the data to ensure our model can generalize beyond the dataset,
                   which is where higher resolution and our custom data generation tools proved essential.
                    For a more in-depth exploration, please visit the
                    <a href="https://github.com/gmarus777/image-to-tex-OCR" target="_blank">GitHub page</a>
                     
                    of our project.
            
            





        </p>

          
        </div>
    </section>
</div>

<div style="text-align: center;">
    <section id="Challenges encountered">
        <h2>Challenges encountered</h2>
        <div style="display: flex; flex-direction: column; align-items: center; max-width: 800px; margin: 0 auto; text-align: left;">
        <p> One of the most significant challenges encountered by others developing similar models is poor generalization to instances outside the dataset.
            To address this issue, we focused on implementing robust preprocessing steps for images.
             Our model's input size during training is limited to strips with a height of 128 pixels and a width of 1024 pixels,
              maintaining a maximum aspect ratio of 8. We then invert colors and apply various transformations using the Albumentations package.
               Inverting colors enables us to pad with a value of zero, which has been demonstrated to facilitate faster model convergence.
                We also observed that higher resolution is advantageous, given that LaTeX code often contains multiple symbols in a relatively
                 small area of the image (such as nested subscripts and superscripts).
            </p>
            
            <p>
            Our current model performs well with single lines of formulas or matrices comprising up to four rows.
             We are in the process of developing a separate model for diagrams, tables, and matrices with more than four rows,
              all of which will be incorporated into our comprehensive paragraph recognition model.
            The original dataset used in the

             <a href="https://im2markup.yuntiandeng.com" target="_blank">the Image-to-Markup project</a>
             
             is of low resolution,
             and employing it for training results in suboptimal model generalization, as noted by others working with similar datasets.
              Our solution involved redeveloping the dataset to generate one with significantly higher resolution,
               which we then randomly compress through transformations during the training phase.
            

                 To improve our model, we employ a higher-resolution dataset and
                  limit the maximum height and width during training to 128 pixels and 1024 pixels,
                   respectively, adhering to a maximum aspect ratio value of 8.
                    We rescale the images to maintain a height of 128 pixels,
                     preserving the aspect ratio provided it stays below the value of 8.
                      For larger aspect ratios, we truncate them to a value of 8.
                       Following this, we apply transformations that introduce random scaling,
                        shifting of images, and various other modifications,
                         such as padding the images to achieve the required strip size of 128 by 1024.
                          These crucial steps significantly enhance the model's adaptability, accuracy, and overall performance.


        </p>

          
        </div>
    </section>
</div>


<div style="text-align: center;">
    <section id="Inspiration">
        <h2>Inspiration </h2>
        <div style="display: flex; flex-direction: column; align-items: center; max-width: 800px; margin: 0 auto; text-align: left;">
        <p>The inspiration for
             <span style="color: black;font-weight: bold">Im</span><span style="color: rgb(42, 150, 140);font-weight: bold">2</span><span style="color: rgb(221, 102, 154);font-weight: bold">Tex</span> 
             project originated from a <a href="https://tlt.psu.edu/faculty/jan-reimann/" target="_blank">collaboration project</a> led by Dr. Jan Reimann at Penn State University, aiming to develop a platform using Jupyter Notebooks for sharing open-source content. We created infrastructure that supports diverse content formats like e-books, interactive notebooks, and quizzes for Canvas integration. Additionally, it offers cost-effective cloud-hosting solutions, enhancing Jupyter Notebooks' usability in educational settings. In Spring 2022, we used this platform to revise the Math 110 Techniques of Calculus course. During this initiative, we identified a need for an open-source OCR tool capable of converting images and PDFs containing mathematical formulas and text into LaTeX code. This realization led us to develop a comprehensive OCR software, now capable of processing mathematical formulas, with ongoing enhancements to include full-page content and handwritten notes.
            </p>
        </div>
    </section>
</div>

    <!-- Add the same scripts and other resources as in your index.html file -->
</body>


<div style="text-align: center;">
    <section id="Future plans and ideas to implement">
        <h2>Future plans and ideas to implement</h2>
        <div style="display: flex; flex-direction: column; align-items: center; max-width: 800px; margin: 0 auto; text-align: left;">
        <p> Coming</p>

          
        </div>
    </section>
</div>

    <!-- Add the same scripts and other resources as in your index.html file -->
</body>




</html>
